# -*- coding: utf-8 -*-
"""ECC_backend.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oKKXKjGpb-GVFsBQibMJhOzKK7zsWON4
"""

# import tensorflow as tf
# from tensorflow.keras import layers, models
# from tensorflow.keras.datasets import cifar10
# from tensorflow.keras.utils import to_categorical

# # Load CIFAR-10 dataset
# (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

# # Normalize pixel values to be between 0 and 1
# train_images, test_images = train_images / 255.0, test_images / 255.0

# # One-hot encode the labels
# train_labels = to_categorical(train_labels, num_classes=10)
# test_labels = to_categorical(test_labels, num_classes=10)

# # Define ResNet model
# def resnet_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True):
#     shortcut = x
#     if conv_shortcut:
#         shortcut = layers.Conv2D(filters, 1, strides=stride)(shortcut)
#         shortcut = layers.BatchNormalization()(shortcut)

#     x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)
#     x = layers.BatchNormalization()(x)
#     x = layers.Activation('relu')(x)

#     x = layers.Conv2D(filters, kernel_size, padding='same')(x)
#     x = layers.BatchNormalization()(x)

#     x = layers.add([x, shortcut])
#     x = layers.Activation('relu')(x)
#     return x

# def resnet(input_shape, num_classes=10):
#     inputs = tf.keras.Input(shape=input_shape)
#     x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)
#     x = layers.BatchNormalization()(x)
#     x = layers.Activation('relu')(x)
#     x = layers.MaxPooling2D(3, strides=2, padding='same')(x)

#     num_blocks_list = [3, 4, 6, 3]
#     for i, num_blocks in enumerate(num_blocks_list):
#         stride = 1 if i == 0 else 2
#         x = resnet_block(x, 64 * 2**i, stride=stride)
#         for _ in range(num_blocks - 1):
#             x = resnet_block(x, 64 * 2**i, conv_shortcut=False)

#     x = layers.GlobalAveragePooling2D()(x)
#     x = layers.Dense(num_classes, activation='softmax')(x)

#     model = models.Model(inputs, x, name='resnet')
#     return model

# # Create ResNet model
# input_shape = train_images.shape[1:]
# model = resnet(input_shape)

# # Compile the model
# model.compile(optimizer=tf.keras.optimizers.Adam(0.001,0.9),
#               loss='binary_crossentropy',
#               metrics=['accuracy'])

# # Print model summary
# model.summary()

# # Train the model
# model.fit(train_images, train_labels, epochs=100, validation_data=(test_images, test_labels))

# print("Hi")

# from google.colab import drive
# drive.mount('/content/gdrive')

# ls

# model.save('/content/gdrive/My Drive/resnet_model.h5')

# from tensorflow import keras

# # Load the saved model
# loaded_model = keras.models.load_model('/content/gdrive/My Drive/resnet_model.h5')

# pip install Flask

# pwd

from flask import Flask, request, jsonify
from PIL import Image
import numpy as np
from tensorflow import keras
from flask_cors import CORS  # Import CORS


app = Flask(__name__)
CORS(app) 
# Load the pre-trained model
loaded_model = keras.models.load_model('./resnet_model.h5')

def preprocess_image(image, target_size):
    # Load the image
    img = image

    # Resize the image
    img = img.resize(target_size)

    # Convert the image to a numpy array
    img_array = np.array(img)

    # Normalize pixel values to the range [0, 1]
    img_array = img_array / 255.0

    # Add an extra dimension to represent the batch size (1 in this case)
    img_array = np.expand_dims(img_array, axis=0)

    return img_array

# @app.route('/predict', methods=['POST'])
# def predict():
#     try:
#         # Receive the image from the UI
#         file = request.files['image']

#         # Specify the target size for resizing
#         target_size = (224, 224)  # Adjust based on your model's input size

#         # Preprocess the image
#         processed_image = preprocess_image(file, target_size)

#         # Make predictions using the loaded model
#         predictions = loaded_model.predict(processed_image)

#         # Return predictions as JSON
#         return jsonify(predictions.tolist())

#     except Exception as e:
#         return jsonify({'error': str(e)})


@app.route('/predict', methods=['POST'])
def predict():
    print("Hi")
    print("Request Body:", request.data)
    # Check if the POST request contains a file
    # if 'file' not in request.files:
    #     return jsonify({'error': 'No file part'})

    file = request.files['image']


    # Specify the target size for resizing
    target_size = (32, 32)  # Adjust based on your model's input size

    # Read the image from the file
    img = Image.open(file.stream)

    # Preprocess the image
    processed_image = preprocess_image(img, target_size)

    # Make predictions using the loaded model
    predictions = loaded_model.predict(processed_image)

    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
#   classes = ['airplane','automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
    my_list = predictions.tolist()[0]
    max_indx = 0
    max_val = 0
    for i in range(len(my_list)):
      if my_list[i] > max_val:
        max_val = my_list[i]
        max_index = i

    print("This is a", classes[max_index])

    # Return predictions as JSON
    return jsonify({'prediction': classes[max_index]})


@app.route('/health_check', methods=['GET'])
def heath_check():
   return "This is health check"

if __name__ == '__main__':
    app.run(debug=True)

# @app.route('/predict', methods=['POST'])
# def predict():
#   # Receive the image from the UI
#   # img = Image.open(open('/content/dog_img.jpg', 'rb'))
#   file = './dog_img.jpg'

#   # Specify the target size for resizing
#   target_size = (32, 32)  # Adjust based on your model's input size

#   # Preprocess the image
#   processed_image = preprocess_image(file, target_size)

#   # Make predictions using the loaded model
#   predictions = loaded_model.predict(processed_image)

#   classes = ['airplane','automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
#   my_list = predictions.tolist()[0]
#   max_indx = 0
#   max_val = 0
#   for i in range(len(my_list)):
#     if my_list[i] > max_val:
#       max_val = my_list[i]
#       max_index = i

#   # Return predictions as JSON
#   print("This is a", classes[max_index])

# if __name__ == '__main__':
#     # app.run(debug=True)

#     predict()

